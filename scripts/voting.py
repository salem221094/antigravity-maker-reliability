#!/usr/bin/env python3
"""
MAKER Voting Utility: First-to-ahead-by-k consensus voting.

Based on the MAKER framework from "Solving a Million-Step LLM Task with Zero Errors".
Uses sequential probability ratio test (SPRT) inspired voting for high-reliability decisions.
"""

from collections import Counter
from typing import List, Optional, Callable, TypeVar, Any
import hashlib

T = TypeVar('T')


def vote_until_consensus(
    candidates: List[T],
    k: int = 3,
    equivalence_fn: Optional[Callable[[T, T], bool]] = None,
    max_samples: int = 100
) -> Optional[T]:
    """
    Select a winner using first-to-ahead-by-k voting.
    
    A candidate wins when it has been selected k more times than any other candidate.
    This provides mathematically bounded error rates even with imperfect per-step accuracy.
    
    Args:
        candidates: List of candidate responses to vote on
        k: Margin required to win (higher = more reliable, but more expensive)
            - k=3: Standard reliability (~99.9% with p=0.7)
            - k=5: High reliability (~99.999% with p=0.7)
            - k=7: Mission-critical (~99.99999% with p=0.7)
        equivalence_fn: Optional function to determine if two candidates are equivalent.
                       If None, uses exact equality.
        max_samples: Maximum candidates to consider before giving up
    
    Returns:
        The winning candidate, or None if no consensus reached within max_samples
    
    Example:
        >>> candidates = ["move disk 1 to C", "move disk 1 to C", "move disk 1 to B"]
        >>> winner = vote_until_consensus(candidates, k=2)
        >>> print(winner)  # "move disk 1 to C"
    """
    if not candidates:
        return None
    
    # Normalize candidates for comparison
    if equivalence_fn is None:
        # Use hash-based grouping for exact matches
        votes: Counter = Counter()
        canonical: dict = {}  # hash -> original value
        
        for candidate in candidates[:max_samples]:
            # Create hashable key
            if isinstance(candidate, (str, int, float, bool, type(None))):
                key = candidate
            else:
                # For complex objects, use string representation hash
                key = hashlib.md5(str(candidate).encode()).hexdigest()
            
            votes[key] += 1
            if key not in canonical:
                canonical[key] = candidate
            
            # Check for winner
            if len(votes) >= 2:
                sorted_votes = votes.most_common(2)
                leader, leader_count = sorted_votes[0]
                _, runner_up_count = sorted_votes[1]
                
                if leader_count - runner_up_count >= k:
                    return canonical[leader]
            elif votes[key] >= k:
                # Only one candidate so far, and it has k votes
                return canonical[key]
        
        # No clear winner within current candidates
        if len(candidates) >= max_samples and votes:
            # Only return most common as a fallback when we've exhausted everything
            return canonical[votes.most_common(1)[0][0]]
        return None
    else:
        # Use equivalence function for semantic matching
        groups: List[List[T]] = []
        
        for candidate in candidates[:max_samples]:
            matched = False
            for group in groups:
                if equivalence_fn(candidate, group[0]):
                    group.append(candidate)
                    matched = True
                    break
            
            if not matched:
                groups.append([candidate])
            
            # Check for winner
            if len(groups) >= 2:
                groups.sort(key=len, reverse=True)
                if len(groups[0]) - len(groups[1]) >= k:
                    return groups[0][0]
            elif len(groups) == 1 and len(groups[0]) >= k:
                return groups[0][0]
        
        # Fallback when exhausted
        if len(candidates) >= max_samples and groups:
            groups.sort(key=len, reverse=True)
            return groups[0][0]
        return None


def calculate_required_k(
    total_steps: int,
    per_step_accuracy: float = 0.8,
    target_success_rate: float = 0.99
) -> int:
    """
    Calculate the minimum k needed for a given reliability target.
    
    Based on the MAKER scaling law: k_min grows logarithmically with total steps.
    
    Args:
        total_steps: Total number of steps in the task
        per_step_accuracy: Probability of correct answer per step (p)
        target_success_rate: Desired overall success probability
    
    Returns:
        Minimum k value needed
    
    Example:
        >>> k = calculate_required_k(1000000, per_step_accuracy=0.8, target_success_rate=0.99)
        >>> print(k)  # Approximately 11
    """
    import math
    
    if per_step_accuracy <= 0.5:
        raise ValueError("per_step_accuracy must be > 0.5 for voting to work")
    
    # From MAKER paper equation 14 (corrected):
    # k_min = ceil(log(s * t / (1 - t)) / (2 * log(p / (1 - p))))
    # Actually, Eq 12 and 13 define p_full. Eq 14 is the derived k_min.
    
    p = per_step_accuracy
    t = target_success_rate
    s = total_steps
    
    # We want (1 - ((1-p)/p)^k)^s >= t
    # 1 - ((1-p)/p)^k >= t^(1/s)
    # ((1-p)/p)^k <= 1 - t^(1/s)
    # k * log((1-p)/p) <= log(1 - t^(1/s))
    # k >= log(1 - t^(1/s)) / log((1-p)/p)
    
    import math
    eps = 1 - math.pow(t, 1/s)
    k_min = math.ceil(math.log(eps) / math.log((1 - p) / p))
    return max(1, k_min)


def estimate_expected_cost(
    total_steps: int,
    k: int,
    per_step_accuracy: float = 0.8,
    cost_per_call: float = 1.0
) -> float:
    """
    Estimate the expected cost of running MAKER with given parameters.
    
    Args:
        total_steps: Total number of steps in the task
        k: Voting margin
        per_step_accuracy: Probability of correct answer per step
        cost_per_call: Cost of a single LLM call (in any unit)
    
    Returns:
        Expected total cost
    
    Note:
        Cost scales as O(k * s) where s is total steps.
        The key insight is that k grows only logarithmically with s,
        so total cost is approximately O(s * log(s)).
    """
    # Expected samples per step for first-to-k voting (simplified)
    # From random walk theory: E[samples] â‰ˆ k / (2p - 1) for p > 0.5
    p = per_step_accuracy
    expected_samples_per_step = k / (2 * p - 1)
    
    return total_steps * expected_samples_per_step * cost_per_call


if __name__ == "__main__":
    # Demo
    print("=== MAKER Voting Utility Demo ===\n")
    
    # Example 1: Simple voting
    responses = ["A", "A", "B", "A", "C", "A", "B"]
    winner = vote_until_consensus(responses, k=2)
    print(f"Candidates: {responses}")
    print(f"Winner (k=2): {winner}\n")
    
    # Example 2: Calculate required k for 1M steps
    k_needed = calculate_required_k(1_000_000, per_step_accuracy=0.8, target_success_rate=0.99)
    print(f"For 1M steps with 80% accuracy, need k={k_needed} for 99% success\n")
    
    # Example 3: Cost estimation
    cost = estimate_expected_cost(1_000_000, k=k_needed, per_step_accuracy=0.8)
    print(f"Expected cost: {cost:,.0f} LLM calls")
